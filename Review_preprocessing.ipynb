{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4aee015",
   "metadata": {},
   "source": [
    "## Loading Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6e54a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Get today's date and format it\n",
    "today = datetime.date.today()\n",
    "formatted_today = today.strftime(\"%Y%m%d\")  # Format as YYYYMMDD\n",
    "\n",
    "df_1 = pd.read_csv('detailed_scrape_master.csv')\n",
    "df_2 = pd.read_csv(f'coast_restaurant_reviews_{formatted_today}.csv')\n",
    "\n",
    "df = pd.concat([df_2, df_1], ignore_index=True)\n",
    "\n",
    "df_cleaned = df.drop_duplicates('Review Text', keep='first')\n",
    "\n",
    "# Reset the index if needed\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_cleaned.to_csv(f'detailed_scrape_master.csv', index=False, encoding='utf-8')\n",
    "\n",
    "df = pd.read_csv('detailed_scrape_master.csv')\n",
    "\n",
    "# Convert score columns to numeric\n",
    "df['Food'] = pd.to_numeric(df['Food'], errors='coerce')\n",
    "df['Service'] = pd.to_numeric(df['Service'], errors='coerce')\n",
    "df['Atmosphere'] = pd.to_numeric(df['Atmosphere'], errors='coerce')\n",
    "\n",
    "df.drop(columns=['Kid-friendliness'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47806c98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Staff list and Normalizing Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fb4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a54d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c5a4e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your staff lists and misspelling map\n",
    "servers = ['andrea', 'andrew', 'ben', 'ben r', 'ben w',\n",
    "           'betty', 'blaine', 'brad', 'brooke', 'caili',\n",
    "           'carmen', 'chris', 'gloria', 'isabel',\n",
    "           'isabella', 'jacob', 'jesse', 'jess', 'josh', 'khalil',\n",
    "           'laura', 'laura b', 'laura c', 'michael', 'peter',\n",
    "           'rhonda', 'sallie', 'sam', 'stephen', 'vinny']\n",
    "\n",
    "bar = ['chrissy', 'chung', 'oscar', 'pavlo', 'rafael', 'ryan', 'aimée']\n",
    "\n",
    "managers = ['abhi', 'franklin', 'katya', 'mohit', 'murat', 'natasha', 'lindsay']\n",
    "\n",
    "host = ['anna', 'caren', 'lotty', 'megan', 'nicole', 'sharen']\n",
    "\n",
    "all_staff = servers + bar + managers + host\n",
    "\n",
    "misspelling_map = {\n",
    "    'abby': 'abhi',\n",
    "    'abbi': 'abhi',\n",
    "    'abi': 'abhi',\n",
    "    'aby': 'abhi',\n",
    "    'aimee': 'aimée',\n",
    "    'ami': 'aimée',\n",
    "    'ben royals': 'ben r',\n",
    "    'ben royles': 'ben r',\n",
    "    'ben ward': 'ben w',\n",
    "    'benw' : 'ben w',\n",
    "    'blain': 'blaine',\n",
    "    'blonde ben': 'ben w',\n",
    "    'blond ben': 'ben w',\n",
    "    'bradley': 'brad',\n",
    "    'brook': 'brooke',\n",
    "    'cali': 'caili',\n",
    "    'chris': 'chris',\n",
    "    'chrissy': 'chrissy',\n",
    "    'isobel': 'isabel',\n",
    "    'isabelle': 'isabel',\n",
    "    'jessica': 'jess',\n",
    "    'joshua': 'Josh',\n",
    "    'katja' : 'katya',\n",
    "    'halil': 'khalil',\n",
    "    'khalel': 'khalil',\n",
    "    'khalil': 'khalil',\n",
    "    'launa': 'laura',\n",
    "    'lindsey': 'lindsay',\n",
    "    'michael m': 'michael',\n",
    "    'michele': 'michael',\n",
    "    'paulo': 'pavlo',\n",
    "    'pablo': 'pavlo',\n",
    "    'raf': 'rafael',\n",
    "    'sally': 'sallie',\n",
    "    'stefan': 'stephen',\n",
    "    'stephan': 'stephen',\n",
    "    'stephans': 'stephen',\n",
    "    'tash': 'natasha',\n",
    "}\n",
    "\n",
    "# Apply normalize_text function to normalize the 'Review Text' column\n",
    "def normalize_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove possessive 's (e.g., \"Gloria's\" → \"Gloria\", \"Ben's\" → \"Ben\")\n",
    "    text = re.sub(r\"\\b(\\w+)'s\\b\", r'\\1', text)\n",
    "    # This will also remove cases like: \"dog's\" → \"dog\"\n",
    "\n",
    "    # Remove all non-word characters except spaces (to keep names with dots, e.g., ben.w)\n",
    "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['Normalized Reviews'] = df['Review Text'].apply(normalize_text)\n",
    "\n",
    "def map_misspellings(text):\n",
    "    for misspelling, correct_name in misspelling_map.items():\n",
    "        pattern = r'\\b' + re.escape(misspelling) + r'\\b'\n",
    "        text = re.sub(pattern, correct_name, text)\n",
    "    return text\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_names(mapped_text):\n",
    "    if not isinstance(mapped_text, str):\n",
    "        return []\n",
    "\n",
    "    # Apply misspelling corrections (map any misspelled names to their correct form)\n",
    "    mapped_text = map_misspellings(mapped_text)\n",
    "\n",
    "    # Initialize a set to store unique staff names\n",
    "    mentioned_names = set()\n",
    "\n",
    "    # Check for exact matches in staff lists, allowing for optional possessive 's\n",
    "    for name in all_staff:\n",
    "        # Look for the name with or without an 's' at the end (e.g., \"Gloria's\" or \"Gloria\")\n",
    "        pattern = r'\\b' + re.escape(name) + r\"'?s?\\b\"\n",
    "        if re.search(pattern, mapped_text):\n",
    "            mentioned_names.add(name)\n",
    "\n",
    "    # Handle edge cases like \"laura b\" and \"ben w\" that should be treated specifically\n",
    "    if 'laura b' in mapped_text:\n",
    "        mentioned_names.add('laura b')\n",
    "    if 'laura c' in mapped_text:\n",
    "        mentioned_names.add('laura c')\n",
    "    if 'ben w' in mapped_text:\n",
    "        mentioned_names.add('ben w')\n",
    "\n",
    "    # Ensure no duplicate generic names when specific ones are found (like \"laura\" should be removed if \"laura b\" is found)\n",
    "    if 'laura b' in mentioned_names or 'laura c' in mentioned_names:\n",
    "        mentioned_names.discard('laura')\n",
    "    if 'ben w' in mentioned_names:\n",
    "        mentioned_names.discard('ben')\n",
    "\n",
    "    # Return the list of names mentioned or 'No Name Mentioned' if none were found\n",
    "    return list(mentioned_names) if mentioned_names else ['No Name Mentioned']\n",
    "\n",
    "df['Names Mentioned'] = df['Normalized Reviews'].apply(extract_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0082c6-24d3-4a69-b509-46a467292271",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "3a260323",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import re\n",
    "\n",
    "# Food items set\n",
    "menu_items = [\n",
    "    \"Oysters\", \"Prawn Cocktail\", \"Seafood Tower\", \"Brioche\", \"Crab Cake\", \"Calamari\", \n",
    "    \"Mussels\", \"Carpaccio\", \"Pacific Octopus\", \"Salmon Flatbread\", \"Mushroom Flatbread\", \n",
    "    \"Chowder\", \"Velouté\", \"bisque\", \"Burrata Salad\", \"Caesar Salad\", \"Cobb Salad\", \"Beets Salad\", \n",
    "    \"Fish & Chip Cones\",\"sushi\", \"California Roll\", \"King Salmon Roll\", \"Tuna Roll\", \"A5 Wagyu Roll\", \n",
    "    \"Sablefish Oshi\", \"Dynamite Roll\", \"Hamachi\", \"Masunosuke\", \"Amaebi\", \"A5 Wagyu\", \"Hotate\", \n",
    "    \"Shiro Maguro\", \"Tako\", \"Uni\", \"Hon Maguro\", \"Otoro\", \"Madai\", \"Nigiri Platter\", \"Sashimi Platter\", \n",
    "    \"King Salmon\", \"Sablefish\", \"Branzino\", \"Scallops\", \"Seafood Linguine\", \"Fish & Chips\", \n",
    "    \"Lobster Roll\", \"Steak\", \"Burger\", \"Roasted Chicken\", \"Poke Bowl\", \"Milanese\", \"Sole Piccata\", \n",
    "    \"Vongole\", \"Truffle Fries\", \"Grilled Broccolini\", \"Brussels Sprouts\", \"Banana Cake\", \n",
    "    \"Creme Brulee\", \"Chocolate Mint Cake\", \"Cheesecake\", \"Raspberry Cake\", \"Creme Puff\", \n",
    "    \"Crab Dip\", \"Hamachi Crudo\", \"Salmon Oshi\", \"Negitoro Hand Roll\", \"Lobster Roll\"\n",
    "]\n",
    "\n",
    "# List of specific menus to check\n",
    "menu_keywords = [\n",
    "    \"brunch\", \"lunch\", \"happy hour\", \"dinner\", \"valentines\", \"set menu\", \"lobster night\", \"buy up\"\n",
    "]\n",
    "\n",
    "# Define abbreviations\n",
    "menu_abbreviations = {\n",
    "    \"hh\": \"happy hour\"\n",
    "}\n",
    "\n",
    "def extract_food_mentions_fuzzy(review_text, threshold=80):\n",
    "    found_items = set()\n",
    "    found_menus = set()\n",
    "\n",
    "    # Normalize abbreviations (e.g., \"hh\" -> \"happy hour\")\n",
    "    for abbreviation, full_menu in menu_abbreviations.items():\n",
    "        review_text = review_text.lower().replace(abbreviation, full_menu)\n",
    "\n",
    "    # Tokenize review into potential food words\n",
    "    words = re.findall(r'\\b\\w+\\b', review_text.lower())  # Extract words\n",
    "    \n",
    "    # Check for food items\n",
    "    for word in words:\n",
    "        match, score, _ = process.extractOne(word, menu_items, scorer=fuzz.ratio)  # Use fuzz.ratio for better matching\n",
    "        if score >= threshold:  # Higher threshold means stricter matching\n",
    "            found_items.add(match)\n",
    "    \n",
    "    # Check for specific menu mentions\n",
    "    for menu in menu_keywords:\n",
    "        if menu in review_text.lower():  # Check if the menu keyword is in the review\n",
    "            found_menus.add(menu)\n",
    "    \n",
    "    return list(found_items), list(found_menus)\n",
    "\n",
    "# Apply the function to the 'review_text' column and create new columns\n",
    "df[['Food Mentions', 'Menu Mentions']] = df['Review Text'].apply(lambda x: pd.Series(extract_food_mentions_fuzzy(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "58fbfd2f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define standardization mapping\n",
    "merge_dict = {\n",
    "    \"wagyu beef carpaccio\": \"carpaccio\",\n",
    "    \"beef carpaccio\": \"carpaccio\",\n",
    "    \"oysters on the half shell and lemon drop\": \"oysters\",\n",
    "    \"new england clam chowder\": \"chowder\",\n",
    "    \"mussels & clams\": \"mussels\",\n",
    "    \"mussels and clams\": \"mussels\",\n",
    "    \"coast tower\": \"seafood tower\",\n",
    "    \"fish and chip cones\" : \"Fish & Chip Cones\",\n",
    "    \"fish and chips\" : \"Fish & Chips\",\n",
    "    \"warm banana & coconut butter cake & creme brulee\" : \"Butter Cake & Creme Brulee\"\n",
    "}\n",
    "\n",
    "# Clean and prepare the recommended dishes list\n",
    "df['Recommended dishes'] = df['Recommended dishes'].fillna('')  # Handle NaN values\n",
    "\n",
    "# Apply merge_dict mapping to standardize dish names\n",
    "df['Recommended dishes'] = df['Recommended dishes'].apply(lambda x: [\n",
    "    merge_dict.get(dish.strip().lower(), dish.strip().lower()) for dish in x.split(',') if dish\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "81fb41b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "topics = {\n",
    "    'Service': [\n",
    "        'server', 'service', 'fast', 'experience', 'friendly', 'attentive', 'helpful', 'waiter', 'waitress'\n",
    "    ],\n",
    "    'Food': [\n",
    "        'delicious', 'tasty', 'food', 'tasted', 'order', 'ordered', 'flavor', 'pairing', 'sushi', 'meal'\n",
    "    ],\n",
    "    'Positive': [\n",
    "        'great', 'good', 'amazing', 'superb', 'fantastic', 'excellent', \n",
    "        'wonderful', 'thank', 'highly', 'recommend', 'best', 'impeccable', 'awesome',\n",
    "        'courteous', 'professional', 'phenomenal'\n",
    "    ],\n",
    "    'Negative': [\n",
    "        'poor', 'slow', 'terrible', 'awful', 'bad', 'disgusting', 'dissapointing', 'mediocre'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Double negatives phrases\n",
    "double_negatives = ['not bad', 'not good', 'not great']\n",
    "\n",
    "# Function to categorize reviews based on topic keywords\n",
    "def assign_themes(text, topics):\n",
    "    themes = []\n",
    "    \n",
    "    # Convert the text to lowercase to make the search case-insensitive\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Check for double negatives and adjust sentiment\n",
    "    if any(neg_phrase in text_lower for neg_phrase in double_negatives):\n",
    "        # If double negative, treat as positive\n",
    "        themes.append('Positive')\n",
    "    else:\n",
    "        # Check for positive and negative keywords\n",
    "        for theme, keywords in topics.items():\n",
    "            if any(word in text_lower for word in keywords):\n",
    "                if theme != 'Negative' or 'Positive' in themes:  # Ensure no double counting\n",
    "                    themes.append(theme)\n",
    "                \n",
    "    return themes\n",
    "\n",
    "# Apply the function to create the 'Theme' column\n",
    "df['Theme'] = df['Normalized Reviews'].apply(lambda x: assign_themes(x, topics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b46ed34d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in each dish in the 'Recommended dishes' list\n",
    "df['Recommended dishes'] = df['Recommended dishes'].apply(lambda dishes: [dish.title() for dish in dishes])\n",
    "\n",
    "# Capitalize the first letter of each word in each menu mention in the 'Menu Mentions' list\n",
    "df['Menu Mentions'] = df['Menu Mentions'].apply(lambda mentions: [mention.title() for mention in mentions])\n",
    "\n",
    "# Create a new column for tags by combining extracted food and menu mentions without duplicates\n",
    "df['Tags'] = df.apply(lambda row: list(set(row['Food Mentions']) | set(row['Recommended dishes']) | set(row['Menu Mentions'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739645e1",
   "metadata": {},
   "source": [
    "# Tableau Export - Exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "9c190b25-45f8-4b61-82a4-67b0d9211997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a reversed index\n",
    "df_exploded = df.copy()\n",
    "\n",
    "# Reverse the DataFrame, create a new index, then reverse it back\n",
    "df_exploded['Reversed Index'] = range(len(df_exploded), 0, -1)\n",
    "\n",
    "# Explode the 'Tags' column so each name has its own row\n",
    "df_exploded = df_exploded.explode('Tags')\n",
    "\n",
    "# Explode the 'Names Mentioned' column so each name has its own row\n",
    "df_exploded = df_exploded.explode('Names Mentioned')\n",
    "\n",
    "# Explode the 'Theme' column so each name has its own row\n",
    "df_exploded = df_exploded.explode('Theme')\n",
    "\n",
    "# Explode the 'Menu Mentions' column so each name has its own row\n",
    "df_exploded = df_exploded.explode('Menu Mentions')\n",
    "\n",
    "# Create a dictionary to map text to numerical values\n",
    "star_rating_map = {\n",
    "    '5 stars': 5,\n",
    "    '4 stars': 4,\n",
    "    '3 stars': 3,\n",
    "    '2 stars': 2,\n",
    "    '1 star': 1\n",
    "}\n",
    "\n",
    "# Replace the values in the 'Star Rating' column with numerical values\n",
    "df_exploded['Star Rating'] = df_exploded['Star Rating'].replace(star_rating_map)\n",
    "\n",
    "# Convert the 'Date of Review' column to datetime format\n",
    "df_exploded['Date Of Review'] = pd.to_datetime(df_exploded['Date Of Review'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d32d7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the resulting DataFrame to a CSV file\n",
    "#df_exploded.to_csv('Review_dashboard_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab3dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7d05a6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Names Mentioned\n",
       "[No Name Mentioned]            49\n",
       "[stephen]                      40\n",
       "[ben w]                        26\n",
       "[laura]                        24\n",
       "[peter]                        24\n",
       "[gloria]                       21\n",
       "[isabel]                       17\n",
       "[laura b]                      12\n",
       "[caili]                        10\n",
       "[sallie]                        9\n",
       "[andrea]                        9\n",
       "[sam]                           9\n",
       "[josh]                          8\n",
       "[andrew]                        7\n",
       "[jacob]                         5\n",
       "[khalil]                        4\n",
       "[ryan, aimée]                   2\n",
       "[rhonda]                        2\n",
       "[ben]                           2\n",
       "[aimée]                         2\n",
       "[lindsay, sallie, franklin]     2\n",
       "[ben w, franklin]               1\n",
       "[blaine]                        1\n",
       "[jacob, mohit]                  1\n",
       "[laura, andrea]                 1\n",
       "[franklin]                      1\n",
       "[megan, mohit, gloria]          1\n",
       "[andrea, lindsay]               1\n",
       "[pavlo]                         1\n",
       "[oscar]                         1\n",
       "[jesse]                         1\n",
       "[vinny]                         1\n",
       "[peter, lindsay]                1\n",
       "[chris, peter, lindsay]         1\n",
       "[ben, isabel, lindsay]          1\n",
       "[katya, caili]                  1\n",
       "[katya]                         1\n",
       "[mohit, blaine]                 1\n",
       "[rhonda, mohit]                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Names Mentioned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a7ef6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1418 entries, 0 to 301\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Star Rating         1418 non-null   int64         \n",
      " 1   Review Text         1418 non-null   object        \n",
      " 2   Time Since Review   1418 non-null   object        \n",
      " 3   Date Of Review      330 non-null    datetime64[ns]\n",
      " 4   Time Period         1418 non-null   object        \n",
      " 5   Service type        1005 non-null   object        \n",
      " 6   Meal type           1040 non-null   object        \n",
      " 7   Price per person    1055 non-null   object        \n",
      " 8   Food                1375 non-null   float64       \n",
      " 9   Service             1379 non-null   float64       \n",
      " 10  Atmosphere          1377 non-null   float64       \n",
      " 11  Recommended dishes  1418 non-null   object        \n",
      " 12  Parking space       53 non-null     object        \n",
      " 13  Parking options     53 non-null     object        \n",
      " 14  Normalized Reviews  1418 non-null   object        \n",
      " 15  Names Mentioned     1418 non-null   object        \n",
      " 16  Food Mentions       1418 non-null   object        \n",
      " 17  Menu Mentions       626 non-null    object        \n",
      " 18  Theme               1399 non-null   object        \n",
      " 19  Tags                1140 non-null   object        \n",
      " 20  Reversed Index      1418 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(2), object(15)\n",
      "memory usage: 243.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663d8284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
